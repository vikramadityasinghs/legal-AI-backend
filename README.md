# AI-Powered Legal Document Analysis System

A complete production-ready system for analyzing legal documents using AI agents, specifically designed for Indian Law. The system extracts key information, generates timelines, and provides actionable legal recommendations.

## ğŸ—ï¸ Architecture

### Backend (FastAPI)
- **Document Processing**: PDF and image text extraction
- **AI Agent Pipeline**: Multi-agent analysis system
- **Export Services**: Excel, JSON, and PDF report generation
- **RESTful API**: Complete API for frontend integration

### Frontend Options
1. **Simple Frontend** (`frontend-simple/`): Vanilla JS, no dependencies
2. **React Frontend** (`frontend/`): Modern React with TypeScript (requires npm)

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- Modern web browser
- For React frontend: Node.js 16+ and npm

### 1. Backend Setup

```bash
# Navigate to project root
cd legal-analysis-app

# Configure Python environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install backend dependencies
cd backend
pip install -r requirements.txt

# Start the FastAPI server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Frontend Setup (Simple Version)

```bash
# In a new terminal, navigate to simple frontend
cd legal-analysis-app/frontend-simple

# Start HTTP server
python3 -m http.server 3000

# Open browser to http://localhost:3000
```

### 3. Frontend Setup (React Version - if npm works)

```bash
# Navigate to React frontend
cd legal-analysis-app/frontend

# Install dependencies
npm install

# Start development server
npm start
```

## ğŸ“ Project Structure

```
legal-analysis-app/
â”œâ”€â”€ backend/                     # FastAPI backend
â”‚   â”œâ”€â”€ main.py                 # Main API application
â”‚   â”œâ”€â”€ models.py               # Pydantic data models
â”‚   â”œâ”€â”€ config.py               # Configuration settings
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ services/               # Business logic
â”‚       â”œâ”€â”€ document_processor.py
â”‚       â”œâ”€â”€ ai_agents.py
â”‚       â””â”€â”€ export_service.py
â”œâ”€â”€ frontend/                    # React frontend (TypeScript)
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ services/           # API integration
â”‚   â”‚   â”œâ”€â”€ types/              # TypeScript definitions
â”‚   â”‚   â””â”€â”€ context/            # State management
â”‚   â””â”€â”€ public/
â”œâ”€â”€ frontend-simple/             # Vanilla JS frontend
â”‚   â”œâ”€â”€ index.html              # Main HTML page
â”‚   â”œâ”€â”€ app.js                  # JavaScript logic
â”‚   â””â”€â”€ README.md               # Simple frontend docs
â””â”€â”€ test_api.py                 # API testing script
```

## ğŸ”§ API Endpoints

### Core Endpoints
- `GET /` - Health check
- `POST /upload` - Upload documents for analysis
- `POST /analyze/{job_id}` - Start analysis process
- `GET /status/{job_id}` - Check analysis progress
- `GET /results/{job_id}` - Retrieve analysis results
- `GET /export/{job_id}?format={format}` - Export results
- `DELETE /jobs/{job_id}` - Cancel/delete analysis job

### Supported File Formats
- **Documents**: PDF
- **Images**: JPG, JPEG, PNG

### Export Formats
- **Excel**: Comprehensive report with multiple sheets
- **JSON**: Raw analysis data
- **PDF**: Formatted summary report

## ğŸ¤– AI Agent Pipeline

The system uses a multi-agent approach for comprehensive analysis:

### 1. Document Summarizer Agent
- Extracts case metadata (title, number, court, parties)
- Generates case summary
- Identifies key legal concepts

### 2. Enhanced Date Extractor Agent
- Extracts chronological events
- Associates events with specific parties
- Maintains temporal relationships

### 3. Legal Recommendations Agent
- Provides actionable legal advice
- Categorizes recommendations by priority
- Offers strategic guidance

## ğŸ§ª Testing

### API Testing
```bash
# Run comprehensive API tests
python test_api.py
```

### Manual Testing
1. Start both backend and frontend
2. Navigate to `http://localhost:3000`
3. Upload a legal document (PDF/image)
4. Monitor analysis progress
5. Review results and export reports

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file in the backend directory:

```env
# AI/LLM Configuration
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key

# File Upload Limits
MAX_FILE_SIZE_MB=50
ALLOWED_EXTENSIONS=pdf,jpg,jpeg,png

# Export Configuration
EXPORT_DIR=./exports
```

### Backend Configuration
Edit `backend/config.py` to customize:
- File upload limits
- AI model selection
- Export settings
- Logging configuration

## ğŸš€ Production Deployment

### Backend Deployment
```bash
# Install production dependencies
pip install gunicorn

# Run with Gunicorn
gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### Frontend Deployment
```bash
# Simple frontend - serve static files
# React frontend - build and serve
npm run build
```

### Docker Support
```dockerfile
# Backend Dockerfile example
FROM python:3.12-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ› ï¸ Development

### Adding New AI Agents
1. Create agent class in `services/ai_agents.py`
2. Implement required methods: `analyze()`, `parse_response()`
3. Add to orchestrator pipeline
4. Update models in `models.py`

### Frontend Customization
- **Simple**: Edit HTML/CSS/JS directly
- **React**: Standard React component development

### Database Integration
For production, replace in-memory job storage:
```python
# Replace jobs dict with database
from sqlalchemy import create_engine
# Implement job persistence
```

## ğŸ“Š Features

### Document Analysis
- âœ… PDF text extraction
- âœ… Image OCR processing
- âœ… Multi-page document support
- âœ… Legal document structure recognition

### AI Analysis
- âœ… Case summary generation
- âœ… Event timeline extraction
- âœ… Legal recommendation engine
- âœ… Party-specific analysis

### Export & Reporting
- âœ… Excel reports with multiple sheets
- âœ… JSON data export
- âœ… PDF summary reports
- âœ… Timeline visualization

### User Interface
- âœ… Drag & drop file upload
- âœ… Real-time progress tracking
- âœ… Responsive design
- âœ… Export management

## ğŸ› Troubleshooting

### Common Issues

#### Backend Won't Start
```bash
# Check Python environment
python --version
pip list

# Verify dependencies
pip install -r requirements.txt
```

#### Frontend Dependencies Failed
- Use the simple frontend (`frontend-simple/`) as an alternative
- Check npm registry configuration
- Try yarn instead of npm

#### Analysis Takes Too Long
- Check AI API quotas and limits
- Verify document size and complexity
- Monitor backend logs for errors

#### CORS Issues
- Ensure frontend URL is in CORS allowed origins
- Check browser developer console for errors

### Logging
Backend logs include:
- Document processing status
- AI agent execution details
- Error messages and stack traces

## ğŸ“ Contributing

1. Fork the repository
2. Create a feature branch
3. Implement changes with tests
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For issues and questions:
1. Check the troubleshooting section
2. Review API documentation
3. Check backend logs for errors
4. Test with provided sample files

## ğŸ”„ Version History

- **v1.0.0**: Initial release with complete AI pipeline
  - Multi-agent document analysis
  - React and vanilla JS frontends
  - Export functionality
  - Production-ready backend
